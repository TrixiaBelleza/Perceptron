# Perceptron
A perceptron is a form of simple neural network, consisting of a single neuron that takes a feature vector with n coordinates, assigns each coordinate with a corresponding weight, and outputs the feature vectorâ€™s classification based on a threshold function. Perceptrons were conceptualized by Frank Rosenblatt in 1957, and it was one of the first neural networks to be implemented. Perceptrons only work on linearly separable data. If the training data is not linearly separable, the perceptron algorithm will not converge.
